import json
import re
import subprocess
import os
import sys
import shutil
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont, ImageFilter

# ==========================================
# 1. ç”¨æˆ·é…ç½®åŒºåŸŸ
# ==========================================

CONFIG = {
    # è·¯å¾„é…ç½®é›†ä¸­ç®¡ç†ï¼Œè·¯å¾„ä¸è¦æ›´æ”¹
    # æ•°æ®æºæ–‡ä»¶è·¯å¾„ (é‡Œé¢å«æœ‰JSONæ•°ç»„ï¼Œç”¨äºç¡®å®šå‰ªè¾‘ç‰‡æ®µ)
    "data_source": "Data_source.txt",     

    # è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„, ç¨‹åºä¼šè‡ªåŠ¨åœ¨æ­¤æ–‡ä»¶å¤¹ä¸‹æŸ¥æ‰¾ï¼š
    # 1. å”¯ä¸€çš„è§†é¢‘æ–‡ä»¶ (.mp4, .flv, .mkv, .mov, .ts)
    # 2. å”¯ä¸€çš„å­—å¹•æ–‡ä»¶ (.srt)
    # 3. è¾“å‡ºæ—¶ä¼šè‡ªåŠ¨æå–è¿™ä¸ªæ–‡ä»¶å¤¹çš„åå­—ï¼Œåœ¨ output_dir ä¸‹åˆ›å»ºåŒåæ–‡ä»¶å¤¹
    "input_dir": r"",
    
    "output_dir": "workspace/clip_output",

    # --- å­—å¹•ç¼“å†²é…ç½® (æŒ‰å¥å­æ•°é‡) ---
    "padding": {
        "pre_sentences": 5,   # ç‰‡æ®µå‘å‰å»¶ä¼¸çš„å¥å­æ•°é‡
        "post_sentences": 2   # ç‰‡æ®µå‘åå»¶ä¼¸çš„å¥å­æ•°é‡
    },

    # --- [å°é¢å­—ä½“é…ç½®] ---
    "font_path": os.path.join(os.path.dirname(__file__), "assets", "font", "WenYue-XinQingNianTi-W8-J-2.otf"), 

    # --- [è§†é¢‘å­—å¹•æ ·å¼ (ASS)] ---
    "subtitle": {
        # è§†é¢‘æ–¹å‘è®¾ç½®ï¼Œå¡«å†™ï¼š
        # "horizontal" = æ¨ªå± (1920x1080)ï¼ˆBç«™ç»å…¸é£æ ¼ï¼‰
        # "vertical"   = ç«–å± (1080x1920)ï¼ˆç±»ä¼¼äºæŠ–éŸ³ï¼‰
        # å¦‚æœæ˜¯æ¨ªå±ç›´æ’­å°±å¡«"horizontal"ï¼Œç«–å±ç›´æ’­å°±å¡«"vertical"ã€‚å¦‚æœè¿™é‡Œè®¾ç½®é”™äº†ï¼Œé‚£ä¹ˆå­—å¹•ä¼šå˜å¾—å¼‚å¸¸å¤§æˆ–è€…å¼‚å¸¸å°
        "orientation": "horizontal", 

        # è§†é¢‘å­—å¹•å­—ä½“ï¼ˆä½¿ç”¨å‰è¦åœ¨è‡ªå·±ç³»ç»Ÿé‡Œå®‰è£…å­—ä½“ï¼Œå¦åˆ™ç³»ç»Ÿä¼šä½¿ç”¨é»˜è®¤å­—ä½“ï¼‰
        "font_family": "WenYue XinQingNianTi (Authorization Required) W8-J", # æ–°é’å¹´ä½“ï¼ˆæ¨èï¼‰
        # "font_family": "084-SSZhuangYuanTi",  # ä¸Šé¦–çŠ¶å…ƒä½“
        # "font_family": "Jiyucho",  # è‡ªç”±ä½“

        "font_size": 120,          # å­—ä½“å¤§å°  (æ¨èä¸º120)
        "outline_width": 7,        # æè¾¹å®½åº¦ ï¼ˆæ¨èä¸º7ï¼‰  
        "shadow_depth": 2,         # é˜´å½±æ·±åº¦  (æ¨èä¸º2) 
        "margin_v": 50,            # å­—å¹•å’Œç”»é¢åº•éƒ¨çš„è·ç¦»ï¼ˆæ¨èä¸º50ï¼‰

        # å­—å¹•æ ·å¼ï¼š
        # é»„å­—é»‘è‰²æè¾¹ï¼ˆé€šç”¨ï¼‰    
        "primary_color": "&H0000E1FF", 
        "outline_color": "&H00000000", 

        # ç™½å­—é»‘è‰²æè¾¹ï¼ˆé€šç”¨ï¼‰    
        # "primary_color": "&H00FFFFFF",
        # "outline_color": "&H00000000",

        # å˜‰ç„¶ä¸“å±
        # "primary_color": "&H00FFFFFF", 
        # "outline_color": "&H009972F0", 

        # "primary_color": "&H009972F0", 
        # "outline_color": "&H00FFFFFF", 

        # è´æ‹‰ä¸“å±
        # "primary_color": "&H00FFFFFF", 
        # "outline_color": "&H00747DDB", 

        # "primary_color": "&H00747DDB", 
        # "outline_color": "&H00FFFFFF", 

        # ä¹ƒç³ä¸“å±
        # "primary_color": "&H00FFFFFF", 
        # "outline_color": "&H00906657", 

        # "primary_color": "&H00906657", 
        # "outline_color": "&H00FFFFFF", 

        # A-SOULå›¢ä½“
        # "primary_color": "&H00FFFFFF", 
        # "outline_color": "&H00006AFF", 

        # "primary_color": "&H00006AFF", 
        # "outline_color": "&H00FFFFFF", 

        # å¿ƒå®œä¸“å±
        # "primary_color": "&H00FFFFFF", 
        # "outline_color": "&H009555FF",

        # "primary_color": "&H009555FF", 
        # "outline_color": "&H00FFFFFF", 

        # æ€è¯ºä¸“å±  
        # "primary_color": "&H00FFFFFF",
        # "outline_color": "&H00C889A8", 

        # "primary_color": "&H00C889A8", 
        # "outline_color": "&H00FFFFFF",             
    },

    # ==========================================
    # ğŸ¨ å°é¢æ ·å¼é…ç½®åŒºï¼ˆå¦‚æœæ˜¯ç«–å±ï¼Œéœ€è¦æŠŠä½¿ç”¨çš„å°é¢æ ·å¼è°ƒå°ï¼Œè°ƒæ•´title_sizeï¼‰
    # ==========================================
    "cover": {
        "count": 5,  # æ¯ä¸ªè§†é¢‘ç”Ÿæˆçš„å°é¢æ•°é‡
        "active_style": "style1", # å½“å‰ä½¿ç”¨çš„æ ·å¼
        
        # å›¾ç‰‡é…ç½®
        "images": [
            # {
            #     "path": "assets/image/é€Ÿåº¦çº¿.png",
            #     "x": 0.5, "y": 0.5, "anchor": "center", "size": (2000, 1200), "opacity": 1
            # },
            # {
            #     "path": "assets/image/image3.png",
            #     "x": 0.3, "y": 0.4, "anchor": "center", "size": (300, 300), "opacity": 1
            # },
            # {
            #     "path": "assets/image/image3.png",
            #     "x": 0.7, "y": 0.4, "anchor": "center", "size": (300, 300), "opacity": 1
            # }
        ],
        
        # å°é¢æ ·å¼å®šä¹‰
        "style1": {
            "name": "ä¸Šç™½ä¸‹é»„éœ‡æ’¼é£æ ¼",
            "layout": "double",
            "title_position": "split",
            "title_top_y_ratio": 0.2,
            "title_bottom_y_ratio": 0.75,
            "title_size": 150,
            "title_top_color": (255, 255, 255),
            "title_bottom_color": (255, 225, 0),
            "title_stroke_color": (0, 0, 0),
            "title_stroke_width": 12,
            "gradient_start_y": 0.0,
            "gradient_opacity": 0,
            "show_summary": False
        },
        "style2": {
            "name": "ä¸Šé»„ä¸‹ç™½éœ‡æ’¼é£æ ¼",
            "layout": "double",
            "title_position": "split",
            "title_top_y_ratio": 0.2,
            "title_bottom_y_ratio": 0.75,
            "title_size": 150,
            "title_top_color": (255, 255, 0),
            "title_bottom_color": (255, 225, 255),
            "title_stroke_color": (0, 0, 0),
            "title_stroke_width": 12,
            "gradient_start_y": 0.0,
            "gradient_opacity": 0,
            "show_summary": False
        },
        "style3": {
            "name": "å±…ä¸­å¤§å­—é†’ç›®é£æ ¼",
            "layout": "center",
            "title_position": "center",
            "title_y_ratio": 0.7,
            "title_size": 180,
            "title_color": (255, 225, 0),
            "title_stroke_color": (0, 0, 0),
            "title_stroke_width": 12,
            "gradient_start_y": 0.0,
            "gradient_opacity": 10,
            "show_summary": False
        },
        "style4": {
            "name": "è‰ºæœ¯ç®€æ´é£æ ¼",
            "layout": "center",
            "title_position": "center",
            "title_y_ratio": 0.5,
            "title_size": 180,
            "title_color": (255, 255, 255),
            "title_stroke_color": (50, 50, 50),
            "title_stroke_width": 8,
            "gradient_start_y": 0.0,
            "gradient_opacity": 150,
            "show_summary": False,
            "blur_background": True,
            "blur_radius": 3
        }
    }
}

# ==========================================
# å·¥å…·ç±»åŒºåŸŸ (ä¿æŒä¸å˜)
# ==========================================

class SubtitleUtils:
    @staticmethod
    def parse_srt_time(time_str):
        time_str = time_str.replace(',', '.').strip()
        parts = time_str.split(':')
        if len(parts) == 3:
            return int(parts[0]) * 3600 + int(parts[1]) * 60 + float(parts[2])
        elif len(parts) == 2:
            return int(parts[0]) * 60 + float(parts[1])
        else:
            print(f"âš ï¸ æ—¶é—´æ ¼å¼æ— æ³•è¯†åˆ«: {time_str}")
            return 0

    @staticmethod
    def sec_to_ass_time(seconds):
        h = int(seconds // 3600)
        m = int((seconds % 3600) // 60)
        s = int(seconds % 60)
        cs = int((seconds % 1) * 100)
        return f"{h}:{m:02d}:{s:02d}.{cs:02d}"

    @staticmethod
    def sec_to_srt_time(seconds):
        h = int(seconds // 3600)
        m = int((seconds % 3600) // 60)
        s = int(seconds % 60)
        return f"{h:02d}:{m:02d}:{s:02d}"

    @staticmethod
    def parse_srt(srt_path):
        if not srt_path or not os.path.exists(srt_path):
            return []
        with open(srt_path, 'r', encoding='utf-8') as f:
            content = f.read()
        subs = []
        for block in re.split(r'\n\n+', content.strip()):
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                time_match = re.search(r'(\d+:\d+:\d+[,\.]\d+)\s*-->\s*(\d+:\d+:\d+[,\.]\d+)', lines[1])
                if time_match:
                    start = SubtitleUtils.parse_srt_time(time_match.group(1))
                    end = SubtitleUtils.parse_srt_time(time_match.group(2))
                    text = '\n'.join(lines[2:])
                    subs.append({'start': start, 'end': end, 'text': text})
        return subs

    @staticmethod
    def get_expanded_time_range(subtitles, target_start, target_end, pre_count, post_count):
        if not subtitles:
            return target_start, target_end

        core_start_idx = -1
        core_end_idx = -1
        
        for i, sub in enumerate(subtitles):
            if sub['end'] > target_start and sub['start'] < target_end:
                if core_start_idx == -1:
                    core_start_idx = i
                core_end_idx = i
        
        if core_start_idx == -1:
            print("   âš ï¸ è­¦å‘Š: è¯¥æ—¶é—´æ®µå†…æ— åŒ¹é…å­—å¹•,å°†ä½¿ç”¨åŸå§‹æ—¶é—´æˆ³ã€‚")
            return target_start, target_end

        new_start_idx = max(0, core_start_idx - pre_count)
        new_end_idx = min(len(subtitles) - 1, core_end_idx + post_count)

        expanded_start = subtitles[new_start_idx]['start']
        expanded_end = subtitles[new_end_idx]['end']

        final_start = min(expanded_start, target_start)
        final_end = max(expanded_end, target_end)

        return final_start, final_end

    @staticmethod
    def auto_wrap_text(text, max_len):
        """
        å¦‚æœæ–‡æœ¬è¶…è¿‡ max_lenï¼Œåˆ™è‡ªåŠ¨æ’å…¥æ¢è¡Œç¬¦ã€‚
        """
        # æ¸…é™¤åŸæœ‰çš„æ¢è¡Œç¬¦(åŒ…æ‹¬æ™®é€šæ¢è¡Œå’ŒASSæ¢è¡Œ)
        clean_text = text.replace('\r', '').replace('\n', '').replace('\\N', '')
        
        if len(clean_text) <= max_len:
            return clean_text
            
        result = []
        for i in range(0, len(clean_text), max_len):
            result.append(clean_text[i : i + max_len])
        return '\n'.join(result)

    # ================= é‡æ’ç°æœ‰ ASS æ–‡ä»¶çš„æ–¹æ³• =================
    @staticmethod
    def reformat_ass_file(file_path, max_len):
        """
        è¯»å–ç°æœ‰çš„ ASS æ–‡ä»¶ï¼Œä¿ç•™å†…å®¹ï¼Œä»…é‡æ–°è®¡ç®—æ¢è¡Œ
        """
        if not os.path.exists(file_path):
            return

        with open(file_path, 'r', encoding='utf-8-sig') as f:
            lines = f.readlines()

        new_lines = []
        for line in lines:
            # ASS å­—å¹•è¡Œé€šå¸¸ä»¥ "Dialogue:" å¼€å¤´
            if line.startswith('Dialogue:'):
                # Dialogue: Layer,Start,End,Style,Name,MarginL,MarginR,MarginV,Effect,Text
                # æˆ‘ä»¬åªéœ€è¦åˆ†å‰²å‰9ä¸ªé€—å·ï¼Œç¬¬10éƒ¨åˆ†å°±æ˜¯å­—å¹•æ–‡æœ¬(å¯èƒ½åŒ…å«é€—å·)
                parts = line.split(',', 9)
                if len(parts) == 10:
                    original_text = parts[9].strip()
                    # é‡æ–°åº”ç”¨æ¢è¡Œé€»è¾‘
                    wrapped_text = SubtitleUtils.auto_wrap_text(original_text, max_len)
                    final_text = wrapped_text.replace('\n', '\\N')
                    
                    # æ‹¼è£…å›å»
                    parts[9] = final_text + '\n'
                    new_lines.append(','.join(parts))
                else:
                    new_lines.append(line)
            else:
                new_lines.append(line)
        
        # è¦†ç›–å†™å…¥
        with open(file_path, 'w', encoding='utf-8-sig') as f:
            f.writelines(new_lines)
    # ===============================================================

    @staticmethod
    def create_ass_file(subtitles, output_path, start_offset, end_offset, max_char_len):
        s = CONFIG['subtitle']

        if s.get('orientation', 'horizontal') == 'vertical':
            play_res_x = 1080
            play_res_y = 1920
        else:
            play_res_x = 1920
            play_res_y = 1080

        style_line = (
            f"Style: Default,{s['font_family']},{s['font_size']},"
            f"{s['primary_color']},{s['primary_color']},{s['outline_color']},-1,"
            f"-1,0,0,0,100,100,0,0,1,{s['outline_width']},{s['shadow_depth']},2,10,10,{s['margin_v']},1"
        )

        header = f"""[Script Info]
Title: Auto Clip
ScriptType: v4.00+
PlayResX: {play_res_x}
PlayResY: {play_res_y}
ScaledBorderAndShadow: yes

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
{style_line}

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""
        events = []
        clip_duration = end_offset - start_offset
        valid_count = 0

        for sub in subtitles:
            if sub['end'] > start_offset and sub['start'] < end_offset:
                rel_start = max(0, sub['start'] - start_offset)
                rel_end = min(clip_duration, sub['end'] - start_offset)
                start_str = SubtitleUtils.sec_to_ass_time(rel_start)
                end_str = SubtitleUtils.sec_to_ass_time(rel_end)
                
                # ä¼ å…¥åŠ¨æ€çš„ max_char_len
                wrapped_text = SubtitleUtils.auto_wrap_text(sub['text'], max_len=max_char_len)
                text = wrapped_text.replace('\n', '\\N')
                
                events.append(f"Dialogue: 0,{start_str},{end_str},Default,,0,0,0,,{text}")
                valid_count += 1
        
        with open(output_path, 'w', encoding='utf-8-sig') as f:
            f.write(header + '\n'.join(events))
        return valid_count

class CoverGenerator:
    @staticmethod
    def split_title_smartly(title, max_chars=10):
        split_chars = ['!', '!', '?', '?', ',', ',', 'ã€‚', ':']
        for i, char in enumerate(title):
            if char in split_chars and 3 <= i <= len(title) - 3:
                return title[:i+1], title[i+1:]
        mid = len(title) // 2
        return title[:mid], title[mid:]

    @staticmethod
    def add_image_to_cover(base_img, image_config):
        image_path = image_config.get('path', '')
        if not image_path or not os.path.exists(image_path):
            if image_path:
                print(f"  âš ï¸ å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
            return base_img
        
        try:
            overlay_img = Image.open(image_path).convert("RGBA")
            target_size = image_config.get('size')
            if target_size:
                overlay_img = overlay_img.resize(target_size, Image.Resampling.LANCZOS)
            
            opacity = image_config.get('opacity', 1.0)
            if opacity < 1.0:
                alpha = overlay_img.split()[3]
                alpha = alpha.point(lambda p: int(p * opacity))
                overlay_img.putalpha(alpha)
            
            base_width, base_height = base_img.size
            img_width, img_height = overlay_img.size
            
            x = image_config.get('x', 0)
            y = image_config.get('y', 0)
            
            if isinstance(x, float) and 0.0 <= x <= 1.0: x = int(x * base_width)
            else: x = int(x)
            
            if isinstance(y, float) and 0.0 <= y <= 1.0: y = int(y * base_height)
            else: y = int(y)
            
            anchor = image_config.get('anchor', 'top_left').lower()
            anchor_offsets = {
                'top_left': (0, 0), 'top_center': (-img_width // 2, 0), 'top_right': (-img_width, 0),
                'center_left': (0, -img_height // 2), 'center': (-img_width // 2, -img_height // 2),
                'center_right': (-img_width, -img_height // 2),
                'bottom_left': (0, -img_height), 'bottom_center': (-img_width // 2, -img_height),
                'bottom_right': (-img_width, -img_height)
            }
            offset_x, offset_y = anchor_offsets.get(anchor, (0, 0))
            final_x = x + offset_x
            final_y = y + offset_y
            final_x = max(0, min(final_x, base_width - img_width))
            final_y = max(0, min(final_y, base_height - img_height))
            
            base_img.paste(overlay_img, (final_x, final_y), overlay_img)
        except Exception as e:
            print(f"  âš ï¸ å›¾ç‰‡å åŠ å¤±è´¥ ({image_path}): {e}")
        return base_img

    @staticmethod
    def create_aesthetic_cover(video_path, timestamp_sec, cover_text_1, cover_text_2, output_path, style_config):
        temp_img = output_path.with_suffix('.temp.jpg')
        cmd = [
            'ffmpeg', '-ss', str(timestamp_sec), '-i', video_path,
            '-frames:v', '1', '-q:v', '2', '-y', str(temp_img)
        ]
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        if not temp_img.exists(): return

        try:
            img = Image.open(temp_img).convert("RGBA")
            width, height = img.size
            
            if style_config.get('blur_background', False):
                img = img.filter(ImageFilter.GaussianBlur(style_config.get('blur_radius', 3)))
            
            overlay = Image.new('RGBA', img.size, (0,0,0,0))
            draw = ImageDraw.Draw(overlay)

            gradient_start_y = int(height * style_config.get('gradient_start_y', 0.6))
            gradient_opacity = style_config.get('gradient_opacity', 200)
            for y in range(gradient_start_y, height):
                progress = (y - gradient_start_y) / (height - gradient_start_y)
                alpha = int(progress * gradient_opacity)
                draw.line([(0, y), (width, y)], fill=(0, 0, 0, alpha))
            
            try:
                font_path = CONFIG['font_path']
                title_font = ImageFont.truetype(font_path, style_config['title_size'])
            except IOError:
                title_font = ImageFont.load_default()

            layout = style_config.get('layout', 'bottom')
            
            def draw_text_with_multilayer_stroke(draw, position, text, font, fill_color, stroke_color, stroke_width):
                x, y = position
                
                # è·å–ç”»å¸ƒå°ºå¯¸
                img = draw._image
                width, height = img.size
                
                # åˆ›å»ºä¸´æ—¶å›¾å±‚ç”¨äºç»˜åˆ¶æ–‡å­—ä¸»ä½“
                text_layer = Image.new('RGBA', (width, height), (0, 0, 0, 0))
                text_draw = ImageDraw.Draw(text_layer)
                text_draw.text((x, y), text, font=font, fill=fill_color, anchor="mm")
                
                # åˆ›å»ºæè¾¹å›¾å±‚
                stroke_layer = Image.new('RGBA', (width, height), (0, 0, 0, 0))
                stroke_draw = ImageDraw.Draw(stroke_layer)
                stroke_draw.text((x, y), text, font=font, fill=stroke_color, anchor="mm")
                
                # ä½¿ç”¨ MaxFilter è†¨èƒ€æè¾¹å±‚(å¤šæ¬¡åº”ç”¨ä»¥è¾¾åˆ°æ‰€éœ€å®½åº¦)
                for _ in range(stroke_width):
                    stroke_layer = stroke_layer.filter(ImageFilter.MaxFilter(3))
                
                # å°†æè¾¹å±‚å’Œæ–‡å­—å±‚åˆæˆåˆ°åŸç”»å¸ƒ
                img.paste(stroke_layer, (0, 0), stroke_layer)
                img.paste(text_layer, (0, 0), text_layer)
            
            if layout == "double" and style_config.get('title_position') == "split":
                y1 = int(height * style_config.get('title_top_y_ratio', 0.2))
                top_color = style_config.get('title_top_color', style_config.get('title_color', (255, 255, 255)))
                draw_text_with_multilayer_stroke(
                    draw, (width / 2, y1), cover_text_1, title_font,
                    top_color, style_config['title_stroke_color'], style_config['title_stroke_width']
                )
                if cover_text_2:
                    y2 = int(height * style_config.get('title_bottom_y_ratio', 0.75))
                    bottom_color = style_config.get('title_bottom_color', style_config.get('title_color', (255, 255, 255)))
                    draw_text_with_multilayer_stroke(
                        draw, (width / 2, y2), cover_text_2, title_font,
                        bottom_color, style_config['title_stroke_color'], style_config['title_stroke_width']
                    )
            else:
                title_y = int(height * style_config.get('title_y_ratio', 0.85))
                text_width = draw.textlength(cover_text_1, font=title_font)
                if text_width > width - 100:
                    scaled_size = int(style_config['title_size'] * (width - 100) / text_width)
                    title_font = ImageFont.truetype(font_path, scaled_size)
                
                draw_text_with_multilayer_stroke(
                    draw, (width / 2, title_y), cover_text_1, title_font,
                    style_config['title_color'], style_config['title_stroke_color'], style_config['title_stroke_width']
                )

            img = Image.alpha_composite(img, overlay)
            
            images_list = CONFIG['cover'].get('images', [])
            if images_list and len(images_list) > 0:
                for image_config in images_list:
                    if isinstance(image_config, dict):
                        img = CoverGenerator.add_image_to_cover(img, image_config)

            final_img = img.convert('RGB')
            final_img = final_img.filter(ImageFilter.SHARPEN)
            final_img.save(output_path, quality=95)
        except Exception as e:
            print(f"âš ï¸ å°é¢ç”Ÿæˆå¤±è´¥: {e}")
        finally:
            if temp_img.exists(): temp_img.unlink()

    @staticmethod
    def create_multiple_covers(video_path, start_sec, end_sec, cover_text_1, cover_text_2, base_output_path, cover_count):
        duration = end_sec - start_sec
        if cover_count <= 0: return []
        
        active_style = CONFIG['cover']['active_style']
        style_config = CONFIG['cover'].get(active_style, CONFIG['cover']['style1'])
        
        print(f"   ä½¿ç”¨å°é¢æ ·å¼: {style_config.get('name', active_style)}")
        
        if cover_count == 1: positions = [0.5]
        else: positions = [0.2 + (0.6 / (cover_count - 1)) * i for i in range(cover_count)]
        
        generated_covers = []
        for i, pos in enumerate(positions, 1):
            timestamp = start_sec + duration * pos
            output_path = base_output_path.parent / f"{base_output_path.stem}_cover{i}{base_output_path.suffix}"
            CoverGenerator.create_aesthetic_cover(
                video_path, timestamp, cover_text_1, cover_text_2, output_path, style_config
            )
            if output_path.exists(): generated_covers.append(output_path)
        
        if generated_covers: print(f"   å·²ç”Ÿæˆ {len(generated_covers)} å¼ å°é¢")
        return generated_covers

class VideoProcessor:
    def __init__(self):
        self.base_dir = Path(CONFIG['output_dir'])
        self.base_dir.mkdir(exist_ok=True, parents=True)
        self.all_subs = []
        if os.path.exists(CONFIG['srt_file']):
            self.all_subs = SubtitleUtils.parse_srt(CONFIG['srt_file'])
        else:
            print("âŒ é”™è¯¯: æœªæ‰¾åˆ° SRT å­—å¹•æ–‡ä»¶!")

    def process_clip(self, index, clip_data):
        time_range = clip_data['timestamp']
        start_str, end_str = time_range.split('-')
        
        original_start_sec = SubtitleUtils.parse_srt_time(start_str)
        original_end_sec = SubtitleUtils.parse_srt_time(end_str)

        pre_sentences = CONFIG['padding']['pre_sentences']
        post_sentences = CONFIG['padding']['post_sentences']
        
        actual_start_sec, actual_end_sec = SubtitleUtils.get_expanded_time_range(
            self.all_subs, original_start_sec, original_end_sec, pre_sentences, post_sentences
        )
        actual_duration = actual_end_sec - actual_start_sec

        safe_title = re.sub(r'[\\/:*?"<>|]', '_', clip_data['title'])
        base_name = f"{safe_title}"
        output_video = self.base_dir / f"{base_name}.mp4"
        output_cover = self.base_dir / f"{base_name}.jpg"
        ass_file = self.base_dir / f"{base_name}.ass"

        print(f"\nğŸ¬ [{index}] {clip_data['title']}")
        print(f"   ç¼“å†²ç­–ç•¥: å‘å‰{pre_sentences}å¥ | å‘å{post_sentences}å¥")
        print(f"   å‰ªè¾‘èŒƒå›´: {SubtitleUtils.sec_to_srt_time(actual_start_sec)} --> {SubtitleUtils.sec_to_srt_time(actual_end_sec)}ï¼Œåˆ‡ç‰‡æ—¶é•¿: {actual_duration:.2f}ç§’")

        # ================= è®¡ç®—å­—æ•°é™åˆ¶ =================
        if CONFIG['subtitle'].get('orientation', 'horizontal') == 'vertical':
            max_char_len = 14
        else:
            max_char_len = 24
        # ===============================================

        has_subs = False
        
        if ass_file.exists():
            # åœºæ™¯ A: å­—å¹•æ–‡ä»¶å·²å­˜åœ¨
            print(f"   âœ… æ£€æµ‹åˆ°å·²æœ‰å­—å¹•æ–‡ä»¶: {ass_file.name}")
            
            # [å…³é”®ä¿®æ”¹] è°ƒç”¨é‡æ’å‡½æ•°ï¼Œç›´æ¥ä¿®æ”¹æ–‡ä»¶
            SubtitleUtils.reformat_ass_file(ass_file, max_char_len)
            
            has_subs = True
        else:
            # åœºæ™¯ B: ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œä» SRT ç”Ÿæˆå­—å¹•
            if self.all_subs:
                # æ³¨æ„ï¼šè¿™é‡Œå¤šä¼ äº†ä¸€ä¸ª max_char_len å‚æ•°
                count = SubtitleUtils.create_ass_file(self.all_subs, ass_file, actual_start_sec, actual_end_sec, max_char_len)
                if count > 0: has_subs = True
            else:
                print("   âš ï¸ æ— å­—å¹•æºï¼Œè·³è¿‡å­—å¹•ç”Ÿæˆ")

        # å‡†å¤‡ FFmpeg å‘½ä»¤
        ass_path = str(ass_file.absolute()).replace('\\', '/').replace(':', r'\:')
        current_dir = os.getcwd().replace('\\', '/').replace(':', r'\:')
        
        cmd = [
            'ffmpeg', 
            '-ss', str(actual_start_sec), 
            '-t', str(actual_duration),
            '-i', CONFIG['source_video'],
            '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '23',
            '-c:a', 'libmp3lame', '-b:a', '192k'
        ]
        
        if has_subs:
            cmd.extend(['-vf', f"ass='{ass_path}':fontsdir='{current_dir}'"])
            
        cmd.extend(['-y', str(output_video)])

        subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)
        
        cover_count = CONFIG['cover']['count']
        cover_text_1 = clip_data.get('cover_text_1', '')
        cover_text_2 = clip_data.get('cover_text_2', '')
        
        if not cover_text_1:
            cover_text_1 = clip_data.get('title', 'æœªå‘½åç‰‡æ®µ')
        
        CoverGenerator.create_multiple_covers(
            CONFIG['source_video'], original_start_sec, original_end_sec,
            cover_text_1, cover_text_2, output_cover, cover_count
        )

# ==========================================
# 2. ä¸»ç¨‹åºå…¥å£
# ==========================================

def auto_detect_files(input_dir):
    """è‡ªåŠ¨æ‰«ææ–‡ä»¶å¤¹ä¸‹çš„è§†é¢‘å’Œå­—å¹•æ–‡ä»¶"""
    print(f"æ­£åœ¨æ‰«ææ–‡ä»¶å¤¹: {input_dir}")
    if not os.path.exists(input_dir):
        print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {input_dir}")
        sys.exit(1)
        
    files = os.listdir(input_dir)
    # æ”¯æŒçš„è§†é¢‘æ ¼å¼ï¼ŒåŒ…å« FLV
    video_exts = ('.mp4', '.flv', '.mkv', '.mov', '.ts')
    
    videos = [f for f in files if f.lower().endswith(video_exts)]
    srts = [f for f in files if f.lower().endswith('.srt')]
    
    video_path = None
    srt_path = None
    
    # è§†é¢‘æ£€æµ‹
    if len(videos) == 0:
        print("âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶ (.mp4/.flv/.mkv ç­‰)")
        sys.exit(1)
    elif len(videos) > 1:
        print(f"âŒ æ‰¾åˆ°å¤šä¸ªè§†é¢‘æ–‡ä»¶ï¼Œæ— æ³•ç¡®å®šä½¿ç”¨å“ªä¸ª: {videos}")
        sys.exit(1)
    else:
        video_path = os.path.join(input_dir, videos[0])
        print(f"âœ… é”å®šè§†é¢‘: {videos[0]}")
        
    # å­—å¹•æ£€æµ‹
    if len(srts) == 0:
        print("âš ï¸ æœªæ‰¾åˆ°SRTå­—å¹•æ–‡ä»¶ï¼Œå°†ä¸å†™å…¥å­—å¹•")
    elif len(srts) > 1:
        print(f"âŒ æ‰¾åˆ°å¤šä¸ªSRTæ–‡ä»¶ï¼Œæ— æ³•ç¡®å®šä½¿ç”¨å“ªä¸ª: {srts}")
        sys.exit(1)
    else:
        srt_path = os.path.join(input_dir, srts[0])
        print(f"âœ… é”å®šå­—å¹•: {srts[0]}")
        
    return video_path, srt_path

def main():
    # 1. è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶å¹¶æ›´æ–°é…ç½®
    input_dir = CONFIG['input_dir']
    video_file, srt_file = auto_detect_files(input_dir)
    
    # å°†æ£€æµ‹åˆ°çš„è·¯å¾„æ³¨å…¥åˆ° CONFIG ä¸­ï¼Œä»¥ä¾¿å…¼å®¹åç»­ä»£ç 
    CONFIG['source_video'] = video_file
    CONFIG['srt_file'] = srt_file

    # ================= è‡ªåŠ¨æ›´æ–°è¾“å‡ºè·¯å¾„ =================
    # è·å–è¾“å…¥æ–‡ä»¶å¤¹çš„åç§°
    folder_name = os.path.basename(os.path.normpath(input_dir))
    CONFIG['output_dir'] = os.path.join(CONFIG['output_dir'], folder_name)

    # ----------------- [ä¿®æ”¹] æ¸…ç†é€»è¾‘ -----------------
    output_path_obj = Path(CONFIG['output_dir'])
    
    if output_path_obj.exists():
        print(f"ğŸ§¹ æ£€æµ‹åˆ°è¾“å‡ºç›®å½•å·²å­˜åœ¨ï¼Œæ­£åœ¨æ¸…ç†è§†é¢‘å’Œå°é¢ (ä¿ç•™ .ass å­—å¹•)...")
        # éå†ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
        for file_path in output_path_obj.iterdir():
            if file_path.is_file():
                # æ£€æŸ¥åç¼€åï¼Œå¦‚æœæ˜¯è§†é¢‘æˆ–å›¾ç‰‡åˆ™åˆ é™¤
                if file_path.suffix.lower() in ['.mp4', '.mkv', '.flv', '.jpg', '.png', '.jpeg']:
                    try:
                        file_path.unlink()
                        # print(f"   å·²åˆ é™¤: {file_path.name}")
                    except Exception as e:
                        print(f"âš ï¸ æ— æ³•åˆ é™¤æ–‡ä»¶ {file_path.name}: {e}")
    else:
        # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º
        output_path_obj.mkdir(parents=True, exist_ok=True)
        print(f"âœ… è¾“å‡ºç›®å½•å·²åˆ›å»º")
    # ---------------------------------------------------

    if not os.path.exists(CONFIG['source_video']):
        print(f"âŒ æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {CONFIG['source_video']}")
        return

    data_source_path = CONFIG['data_source']

    # 2. æ£€æŸ¥æ•°æ®æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_source_path):
        print(f"âŒ æœªæ‰¾åˆ°æ•°æ®æºæ–‡ä»¶: {data_source_path}")
        print(" è¯·ç¡®ä¿ Data_source.txt ä½äºæ­£ç¡®ä½ç½®æˆ–åœ¨ CONFIG ä¸­ä¿®æ”¹è·¯å¾„ã€‚")
        return

    # 3. è¯»å–å¹¶è§£æ JSON
    try:
        with open(data_source_path, 'r', encoding='utf-8') as f:
            raw_text = f.read()
        
        json_match = re.search(r'\[.*\]', raw_text, re.S)
        if not json_match:
            print("âŒ æ•°æ®æºæ–‡ä»¶ä¸­æœªæ‰¾åˆ° JSON æ•°ç»„æ ¼å¼ (ä»¥ '[' å¼€å¤´ï¼Œä»¥ ']' ç»“å°¾)")
            return
            
        clips = json.loads(json_match.group())
        
    except json.JSONDecodeError as e:
        print(f"âŒ JSON æ ¼å¼é”™è¯¯: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥ Data_source.txt é‡Œçš„é€—å·ã€å¼•å·æ˜¯å¦æ­£ç¡®ã€‚")
        return
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®æºæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return

    print("=" * 60)
    print("ğŸ¨ è§†é¢‘å‰ªè¾‘ä¸å°é¢ç”Ÿæˆå·¥å…· (è‡ªåŠ¨æ£€æµ‹ + è‡ªåŠ¨å½’æ¡£æ¨¡å¼)")
    print("=" * 60)
    print(f"æ•°æ®æ¥æº: {data_source_path}")
    print(f"è§†é¢‘æ¥æº: {video_file}")
    print(f"è¾“å‡ºç›®å½•: {CONFIG['output_dir']}")
    print(f"å½“å‰å°é¢æ ·å¼: {CONFIG['cover']['active_style']}")
    print(f"æ¯ä¸ªè§†é¢‘ç”Ÿæˆå°é¢æ•°: {CONFIG['cover']['count']}")
    
    images_list = CONFIG['cover'].get('images', [])
    if images_list and len(images_list) > 0:
        print(f"å›¾ç‰‡å åŠ : å·²å¯ç”¨ ({len(images_list)} å¼ )")
    else:
        print(f"å›¾ç‰‡å åŠ : æœªå¯ç”¨")
    
    print(f"å¾…å¤„ç†ç‰‡æ®µæ•°: {len(clips)}")
    print("=" * 60)

    processor = VideoProcessor()
    for i, clip in enumerate(clips, 1):
        try:
            processor.process_clip(i, clip)
        except Exception as e:
            print(f"âŒ å¤„ç†ç‰‡æ®µ {i} æ—¶å‡ºé”™: {e}")

    print("\n" + "=" * 60)
    print(f"âœ… æ‰€æœ‰ç‰‡æ®µå¤„ç†å®Œæ¯•! æ–‡ä»¶ä¿å­˜åœ¨: {CONFIG['output_dir']}")
    print("=" * 60)

if __name__ == "__main__":
    main()